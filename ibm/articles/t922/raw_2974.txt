'''Open source software security''' is the measure of assurance or guarantee in the freedom from danger and risk inherent to an [[open source software]] system.  . 

==The debate==. 
There is an ongoing debate on whether open source software increases software security or is detrimental to its security.  There are a variety of different benefits and drawbacks for both sides of the argument.  There are also a variety of metrics and models to measure the effectiveness of the security.  . 

===Benefits of open source security=== . 

*More people can inspect the source code to find and fix a possible vulnerability.  . 

*[[Proprietary software]] forces the user to accept the level of security that the software vendor is willing to deliver and to accept the rate that patches and updates are released. <ref>Cowan, C. (2003, January). IEEE Security & Privacy. IEEE Security & Privacy, 38-45.  Retrieved May 5, 2008, from IEEE Computer Society Digital Library. </ref> . 

*The end-user of [[Open Source]] code has the ability to change and modify source to implement any extra "features" of security they may wish for a specific use, which can extend to the kernel level if they so wish.  . 

*It is assumed that any compiler that is used creates code that can be trusted, but it has been demonstrated by [[Ken Thompson]] that a compiler can be subverted using an eponymous [[Backdoor_(computing)#Reflections_on_Trusting_Trust|''Thompson hack'']] to create faulty executables that are unwittingly produced by a well-intentioned developer. <ref name="Witten">Witten, B., Landwehr, C., & Caloyannides, M. (2001, September/October). Does Open Source Improve System Security? IEEE Software , 57-61.  Retrieved May 5, 2008, from Computer Database. </ref> With access to the source code for the compiler, the developer has at least the ability to discover if there is any mal-intention.  . 

*[[Kerckhoffs' principle]] is based on the idea that an enemy can steal a secure military system and not be able to compromise the information.  His ideas were the basis for many modern security practices, and followed that [[security through obscurity]] is a bad practice. <ref>Hoepman, J.-H., & Jacobs, B. (2007). Increased Security Through Open Source. Communications of the ACM , 50 (1), 79-83.  Retrieved May 5, 2008, from ACM Digital Library. </ref> . 

===Drawbacks of open source security=== . 

*All people have access to the source code, including potential attackers<ref name="Witten" />.  Any unpatched vulnerability can be used by attackers.  . 

*Simply making source code available does not guarantee review. A good example of this occurring is when [[Marcus J. Ranum|Marcus Ranum]], an expert on security system design and implementation, released his first public firewall toolkit.  At one point in time, there were over 2,000 sites using his toolkit, but only 10 people gave him any feedback or patches<ref>Lawton, G. (2002, March). Open Source Security: Opportunity or Oxymoron? Computer , 18-21.  Retrieved May 5, 2008, from IEEE Computer Society Digital Library. </ref>.  . 

*Having a large amount of eyes reviewing code can "lull a user into a false sense of security"<ref>Hansen, M., Köhntopp, K., & Pfitzmann, A. (2002). The Open Source approach - opportunities and limitations with respect to security and privacy. Computers & Security , 21 (5), 461-471.  Retrieved May 5, 2008, from Computer Database. </ref>. Having many users look at source code does not guarantee that security flaws will be found and fixed.  . 

==Metrics and Models==. 
There are a variety of models and metrics to measure the security of a system.  These are a few methods that can be used to measure the security of software systems.  . 

===Number of days between vulnerabilities===. 
It is argued that a system is most vulnerable after a potential vulnerability is discovered, but before a patch is created.  By measuring the number of days between the vulnerability and when the vulnerability is fixed, a basis can be determined on the security of the system.  There are a few caveats to such an approach: not every vulnerability is equally bad, and fixing a lot of bugs quickly might not be better than only finding a few and taking a little bit longer to fix them, taking into account the operating system, or the effectiveness of the fix<ref name="Witten" />.  . 

===Poisson process===. 
The [[Poisson process]] can be used to measure the rates at which different people find security flaws between open and closed source software.  The process can be broken down by the number of volunteers N<sub>v</sub> and paid reviewers N<sub>p</sub>.  The rates at which volunteers find a flaw is measured by λ<sub>v</sub> and the rate that paid reviewers find a flaw is measured by λ<sub>p</sub>.  The expected time that a volunteer group is expected to find a flaw is 1/(N<sub>v</sub> λ<sub>v</sub>) and the expected time that a paid group is expected to find a flaw is 1/(N<sub>p</sub> λ<sub>p</sub>)<ref name="Witten" />.  . 

===Morningstar model===. 
By comparing a large variety of open source and closed source projects a star system could be used to analyze the security of the project similar to how [[Morningstar, Inc.]] rates mutual funds.  With a large enough data set, statistics could be used to measure the overall effectiveness of one group over the other.  An example of such as system is as follows<ref>Peterson, G. (2008, May 06). Stalking the right software security metric. Retrieved May 18, 2008, from Raindrop: http://1raindrop.typepad.com/1_raindrop/security_metrics/index.html</ref>: . 

*1 Star:  Many security vulnerabilities. 
*2 Stars:  Reliability issues. 
*3 Stars:  Follows best security practices. 
*4 Stars:  Documented secure development process. 
*5 Stars:  Passed independent security review.  . 

===Coverity scan===. 
[[Coverity]] in collaboration with Stanford University has established a new baseline for open source quality and security.  The development is being completed through a contract with the Department of Homeland Security.  They are utilizing innovations in automated defect detection to identify critical types of bugs found in software<ref name="CoverityIndex">Coverity. (n.d.). Accelerating Open Source Quality. Retrieved May 18, 2008, from Scan.Coverity.com: http://scan.coverity.com/index.html</ref>.  The level of quality and security is measured in rungs.  Rungs do not have a definitive meaning, and can change as Coverity releases new tools.  Rungs are based on the progress of fixing issues found by the Coverity Analysis results and the degree of collaboration with Coverity<ref name="CoverityLadder">Coverity. (n.d.). Scan Ladder FAQ. Retrieved May 18, 2008, from Scan.Coverity.com: http://scan.coverity.com/ladder.html</ref>.  They start with Rung 0 and currently go up to Rung 2.  . 

*'''Rung 0'''
The project has been analyzed by Coverity’s Scan infrastructure, but no representatives from the open source software have come forward for the results<ref name="CoverityLadder" />.  . 

*'''Rung 1'''
At rung 1, there is collaboration between Coverity and the development team.  The software is analyzed with a subset of the scanning features to prevent the development team from being overwhelmed<ref name="CoverityLadder" />.  . 

*'''Rung 2'''
There are 11 projects that have been analyzed and upgraded to the status of Rung 2 by reaching zero defects in the first year of the scan.  These projects include: AMANDA, [[Network Time Protocol#Unix|ntp]], [[OpenPAM]], [[OpenVPN]], Overdose, [[Perl]], [[PHP]], [[Postfix (software)|Postfix]], [[Python (programming language)|Python]], [[Samba (software)|Samba]], and [[tcl]]<ref name="CoverityLadder" />.  . 

==External links==. 
* Bruce Schneier: [http://www.schneier.com/crypto-gram-9909.html#OpenSourceandSecurity Open Source and Security] Crypto-Gram Newsletter, September 15, 1999 . 

==References==. 
{{clear}}
{{reflist|2}} . 

{{FOSS}} . 

{{DEFAULTSORT:Open Source Software Security}}
[[Category:Free software|Security]]